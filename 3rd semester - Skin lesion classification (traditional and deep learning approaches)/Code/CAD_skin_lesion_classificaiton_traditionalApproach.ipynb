{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Computer Aided Detection(CAD) for the Diagnosis in SKIN Images\n",
    "* By Abdullah Thabit and Tewodros W. Arega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "from imutils import paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.filters\n",
    "import scipy.stats\n",
    "\n",
    "import scipy.ndimage.morphology\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import progressbar\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import watershed\n",
    "from skimage.transform import match_histograms\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy import ndimage\n",
    "import imutils\n",
    "import mpld3\n",
    "import random\n",
    "import numpy.ma as ma\n",
    "\n",
    "import mahotas as mt\n",
    "from skimage.feature import hog\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import feature\n",
    "\n",
    "from skimage import data\n",
    "from skimage.filters import gabor_kernel\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import time\n",
    "from progress.bar import Bar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify the training and the testing image paths\n",
    "TRAIN_PATH = 'D:/MAIA/MAIA-3rd Semester UdG/CAD/MiniProject-I Classical/Dermoscopy/train'\n",
    "VAL_PATH = 'D:/MAIA/MAIA-3rd Semester UdG/CAD/MiniProject-I Classical/Dermoscopy/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A class that computes the the Local Binary Pattern and returns the normalized histogram\n",
    "\n",
    "''' \n",
    "class LocalBinaryPatterns:\n",
    "    def __init__(self, numPoints, radius):\n",
    "        # store the number of points and radius\n",
    "        self.numPoints = numPoints\n",
    "        self.radius = radius\n",
    " \n",
    "    def describe(self, image, eps=1e-7):\n",
    "        # compute the Local Binary Pattern representation\n",
    "        # of the image, and then use the LBP representation\n",
    "        # to build the histogram of patterns\n",
    "        lbp = feature.local_binary_pattern(image, self.numPoints,\n",
    "            self.radius, method=\"uniform\")\n",
    "        (hist, _) = np.histogram(lbp.ravel(),\n",
    "            bins=np.arange(0, self.numPoints + 3),\n",
    "            range=(0, self.numPoints + 2))\n",
    "\n",
    "        # normalize the histogram\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum() + eps)\n",
    "\n",
    "        # return the histogram of Local Binary Patterns\n",
    "        return hist  \n",
    "\n",
    "'''\n",
    "    Color feature\n",
    "     - Computes the color stastics of RGB, HSV and LAB color spaces of the image:\n",
    "        It calculates the mean, std, skew and kurtosis of each color spaces\n",
    "        \n",
    "        Inputs:\n",
    "            img_RGB: RGB image\n",
    "        Returns:\n",
    "            the color stastics feature vector\n",
    "'''  \n",
    "\n",
    "def meanstd_fun(image):\n",
    "    # mean and std\n",
    "    img_HSV = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)    \n",
    "    img_LAB = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)    \n",
    "\n",
    "    mean_i, std_i = cv2.meanStdDev(image)\n",
    "    mean_hsv, std_hsv = cv2.meanStdDev(img_HSV) \n",
    "    mean_lab, std_lab = cv2.meanStdDev(img_LAB) \n",
    "\n",
    "    skw = np.array([ skew(image[:,:,0].flatten()), skew(image[:,:,1].flatten()), skew(image[:,:,2].flatten()), \n",
    "                    kurtosis(image[:,:,0].flatten()), kurtosis(image[:,:,1].flatten()), kurtosis(image[:,:,2].flatten()),\n",
    "                   skew(img_HSV[:,:,0].flatten()), skew(img_HSV[:,:,1].flatten()), skew(img_HSV[:,:,2].flatten()), \n",
    "                    kurtosis(img_HSV[:,:,0].flatten()), kurtosis(img_HSV[:,:,1].flatten()), kurtosis(img_HSV[:,:,2].flatten()),\n",
    "                    skew(img_LAB[:,:,0].flatten()), skew(img_LAB[:,:,1].flatten()), skew(img_LAB[:,:,2].flatten()), \n",
    "                    kurtosis(img_LAB[:,:,0].flatten()), kurtosis(img_LAB[:,:,1].flatten()), kurtosis(img_LAB[:,:,2].flatten()) ])\n",
    "    skw = np.reshape(skw,(-1,1))\n",
    "\n",
    "    meanstd = np.concatenate((mean_i, std_i, mean_hsv, std_hsv, mean_lab, std_lab, skw), axis=0)            \n",
    "    \n",
    "    return meanstd\n",
    "\n",
    "'''\n",
    " Color feature\n",
    "  - Compute and concatenate the color histogram of RGB, HSV and LAB color spaces of the image:        \n",
    "        \n",
    "        Inputs:\n",
    "            img: RGB image\n",
    "        Returns:\n",
    "            the color histogram feature vector\n",
    "'''\n",
    "def color_hist_fun(image):\n",
    "        \n",
    "    \n",
    "    img_HSV = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    img_LAB = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)    \n",
    "\n",
    "    color_hist = cv2.calcHist([img_HSV], [0, 1, 2], None, [4, 4, 4], [0, 256, 0, 256, 0, 256]) \n",
    "    color_hist_LAB = cv2.calcHist([img_LAB], [0, 1, 2], None, [4, 4, 4], [0, 256, 0, 256, 0, 256]) \n",
    "    color_hist_RGB = cv2.calcHist([image], [0, 1, 2], None, [4, 4, 4], [0, 256, 0, 256, 0, 256]) \n",
    "    color_hist = color_hist.flatten()\n",
    "    color_hist_RGB = color_hist_RGB.flatten()\n",
    "    color_hist_LAB = color_hist_LAB.flatten()\n",
    "    color_hist = np.expand_dims(color_hist, axis=-1)\n",
    "    color_hist_RGB = np.expand_dims(color_hist_RGB, axis=-1)\n",
    "    color_hist_LAB = np.expand_dims(color_hist_LAB, axis=-1)\n",
    "    color_hist = np.concatenate((color_hist, color_hist_LAB, color_hist_RGB), axis = 0)\n",
    "    \n",
    "    return color_hist\n",
    "\n",
    "'''\n",
    "Texture feature\n",
    " Computes Gray-Level Co-Occurrence Matrix (GLCM) \n",
    "     and stastics from GLCM like contrast, correlation, energy, homogeneity and etc of a grayscale image:        \n",
    "     It uses mahotas's haralick glcm.\n",
    "        \n",
    "        Inputs:\n",
    "            img_gray: grayscale image\n",
    "        Returns:\n",
    "            the glcm stastics feature vector\n",
    "'''\n",
    "def glcm_fun(img_gray):\n",
    "    \n",
    "    glcm = mt.features.haralick(img_gray)    \n",
    "    glcm_f = glcm.mean(axis=0)\n",
    "    glcm_f = np.expand_dims(glcm_f,axis=-1)    \n",
    "    \n",
    "    return glcm_f\n",
    "\n",
    "'''\n",
    "Texture feature\n",
    " Computes the histogram of local binary pattern of a grayscale image:              \n",
    "        Inputs:\n",
    "            img_gray: grayscale image\n",
    "            no_points: the number of points in a circularly symmetric neighborhood\n",
    "            radius: radius of the circular neighborhood\n",
    "        Returns:\n",
    "            the lbp feature vector\n",
    "'''  \n",
    "def lbp_fun(img_gray): \n",
    "    \n",
    "    no_points = 8\n",
    "    radius = 3\n",
    "    descr = LocalBinaryPatterns(no_points, radius)        \n",
    "    hist = descr.describe(img_gray)\n",
    "    hist = np.expand_dims(hist, axis=-1)\n",
    "    \n",
    "    return hist\n",
    "'''\n",
    "Shape feature\n",
    " Computes the hu moments of a binary image:              \n",
    "        Inputs:\n",
    "            segmented_image: binary image            \n",
    "        Returns:\n",
    "            the concatenation of the seven hu moments\n",
    "'''\n",
    "def humoments_fun(segmented_image):\n",
    "    \n",
    "    moments = cv2.moments(segmented_image)\n",
    "\n",
    "    # Calculate Hu Moments\n",
    "    huMoments = cv2.HuMoments(moments)\n",
    "\n",
    "    # Log transform of hu moments b/se they have large ranges\n",
    "    for i in range(0,7):\n",
    "        huMoments[i] = -1* np.copysign(1.0, huMoments[i]) * np.log10(abs(huMoments[i])+1e-30)        \n",
    "    \n",
    "    return huMoments  \n",
    "\n",
    "'''\n",
    "Texture feature\n",
    " Computes the mean, std, local energy and mean ampitude of filtered image using gabor kernel:        \n",
    "       \n",
    "        Inputs:\n",
    "            image: grayscale image\n",
    "            kernels: gabor filter kernel bank\n",
    "        Returns:\n",
    "            the gabor feature vector\n",
    "''' \n",
    "def gabor_feature_fun(image, kernels):\n",
    "    \n",
    "    #extracts mean and std from the filtered images\n",
    "    #local energy and mean ampitude\n",
    "    feats = np.zeros((len(kernels), 4), dtype=np.double)\n",
    "    for k, kernel in enumerate(kernels):\n",
    "        filtered = ndi.convolve(image, kernel, mode='wrap')        \n",
    "        feats[k, 0] = filtered.mean()\n",
    "        feats[k, 1] = filtered.var()\n",
    "        feats[k, 2] = np.sum(filtered**2) #energy\n",
    "        feats[k, 3] = np.sum(np.abs(filtered)) #mean ampitude\n",
    "    gabor_feats = np.concatenate((feats[:, 0].flatten(), feats[:, 1].flatten(),\n",
    "                                  feats[:, 2].flatten(), feats[:, 3].flatten()),axis=0)\n",
    "    \n",
    "    return gabor_feats\n",
    "'''\n",
    "Texture feature\n",
    " Computes the histogram of gradients(HOG) of grayscale image:        \n",
    "       \n",
    "        Inputs:\n",
    "            img_gray: grayscale image            \n",
    "        Returns:\n",
    "            the HOG feature vector\n",
    "'''             \n",
    "def hog_fun(img_gray):\n",
    "    \n",
    "    hog_f, hog_image = hog(img_gray, orientations=9, pixels_per_cell=(8, 8), \n",
    "                    cells_per_block=(2, 2), visualize=True, multichannel=False)             \n",
    "    hog_f = np.expand_dims(hog_f, axis=-1)\n",
    "    \n",
    "    return hog_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort filenames for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    '''\n",
    "    alist.sort(key=natural_keys) sorts in human order\n",
    "    http://nedbatchelder.com/blog/200712/human_sorting.html\n",
    "    (See Toothy's implementation in the comments)\n",
    "    '''\n",
    "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Prepare gabor filter bank kernels\n",
    "# with orientation of 0, 1/4*pi, 1/2*pi, 3/4*pi, pi and frequency of 0.05 and 0.25,\n",
    "# sigma of 1 and 3\n",
    "############################################\n",
    "\n",
    "gabor_kernels = []\n",
    "for theta in range(4):\n",
    "    theta = theta / 4. * np.pi\n",
    "    for sigma in (1, 3):\n",
    "        for frequency in (0.05, 0.25):\n",
    "            g_kernel = np.real(gabor_kernel(frequency, theta=theta,\n",
    "                                          sigma_x=sigma, sigma_y=sigma))\n",
    "            gabor_kernels.append(g_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "  Divides the image into equal size regions\n",
    "\n",
    "    Inputs:\n",
    "        image: the image to be divided\n",
    "        stepSize: the number of pixels to “skip” while sliding\n",
    "        windowSize: the width and height of the window we are going to extract from the image\n",
    "    Returns:\n",
    "        the extracted window(region) from the image\n",
    "'''\n",
    "def sliding_window(image,  windowSize, no_channels):\n",
    "    # slide a window across the image, image.shape[1] = 600, image.shape[0] = 450, stepsize_x = windosize[1]  \n",
    "    stepSize_x  = windowSize[1]\n",
    "    stepSize_y = windowSize[0]\n",
    "    for x in range(0, image.shape[0], stepSize_x):\n",
    "        for y in range(0, image.shape[1], stepSize_y):\n",
    "            # yield the current window\n",
    "            if no_channels == 1:                \n",
    "                yield (x, y, image[x:x + windowSize[1], y:y + windowSize[0]])\n",
    "            else:\n",
    "                yield (x, y, image[x:x + windowSize[1], y:y + windowSize[0],:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Hair removal and Segmentation of Skin Lesions:\n",
    "    Input:\n",
    "        img_clahe: contrast enhanced grayscale image\n",
    "        gray: grayscale image with out contrast enhancment\n",
    "        imageRGB: RGB skin image\n",
    "    Returns:\n",
    "        finalwatershed1: segmented mask\n",
    "        inpaintedWhite: grayscale image after hair removal\n",
    "        inpaintedRGB: RGB skin image after hair removal\n",
    "'''\n",
    "def segment_skin(img_clahe, gray, imageRGB):\n",
    "    \n",
    "    ## Hair Removal\n",
    "    \n",
    "    kernelblackhat = cv2.getStructuringElement(1, (17, 17))\n",
    "    blackhat = cv2.morphologyEx(image_clahe, cv2.MORPH_BLACKHAT, kernelblackhat)\n",
    "    ret, threshblackhat = cv2.threshold(blackhat, 10, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    inpaintedWhite = cv2.inpaint(image_clahe, threshblackhat, 1, cv2.INPAINT_TELEA)\n",
    "    inpaintedRGB = cv2.inpaint(imageRGB, threshblackhat, 1, cv2.INPAINT_TELEA)   \n",
    "            \n",
    "    inpaintedWhite = clahe.apply(inpaintedWhite) \n",
    "    \n",
    "    ## Apply Ellipse Mask\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "    mymask = np.zeros_like(inpaintedWhite) \n",
    "    ellipse_mask = cv2.ellipse(mymask, (300,225),(300,225), 0, 0, 360, 1, -1)\n",
    "    (_, thresh) = cv2.threshold(inpaintedWhite, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "\n",
    "    thresh = thresh * ellipse_mask\n",
    "    kernel3 = cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel3)\n",
    "    \n",
    "    # Seed selection using distance transform\n",
    "    D = ndimage.distance_transform_edt(thresh)\n",
    "    localMax = peak_local_max(D, indices=False, min_distance=20,  labels=thresh,\n",
    "                              num_peaks_per_label = 10)\n",
    "\n",
    "    # creating marker or seed from localmax\n",
    "    markers = ndimage.label(localMax)[0]\n",
    "    markers = np.uint16(markers)\n",
    "\n",
    "    # Mask the seeds in the corners \n",
    "    markers[:100,:] = 0 \n",
    "    markers[:,500:] = 0                \n",
    "    markers[:,:100] = 0\n",
    "    markers[350:,:] = 0\n",
    "    \n",
    "    # Watershed Segmentation and Post Processing\n",
    "    kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT,(5,5))\n",
    "    label_watershed = watershed(-D, markers, mask=thresh) \n",
    "    final_watershed = (label_watershed > 0) * 1\n",
    "    final_watershed = final_watershed.astype(np.uint8)\n",
    "    final_watershed = cv2.morphologyEx(final_watershed, cv2.MORPH_DILATE, kernel2, iterations = 2)\n",
    "    final_watershed1 = final_watershed\n",
    "    final_watershed1 = final_watershed1.astype(np.uint8)\n",
    "    final_watershed1 = cv2.morphologyEx(final_watershed1, cv2.MORPH_DILATE, kernel2, iterations = 2) # to view markers\n",
    "    ########################################################\n",
    "    # Filling Holes\n",
    "    ########################################################\n",
    "    contour,hier  = cv2.findContours(final_watershed1,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contour:            \n",
    "        cv2.drawContours(final_watershed1,[cnt],0,255,-1)    \n",
    "        \n",
    "    return final_watershed1, inpaintedWhite, inpaintedRGB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the window size and number of regions for sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn import svm\n",
    "\n",
    "total_no = 4800\n",
    "\n",
    "#Sliding window size\n",
    "resize = 1\n",
    "winW = np.int(600/resize)\n",
    "winH = np.int(450/resize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "dirs_all = os.listdir(TRAIN_PATH)\n",
    "dirs_all.sort()\n",
    "\n",
    "humoments_feature = []\n",
    "lbp_feature = []\n",
    "glcm_feature = []\n",
    "labels = []\n",
    "meanstd_feature = []\n",
    "gabor_feature = []\n",
    "color_hist_feature = []\n",
    "hog_feature = []\n",
    "\n",
    "max_count = 6000\n",
    "\n",
    "# set up the progress bar\n",
    "widgets = [\"Reading: \", progressbar.Percentage(), \" \", progressbar.Bar(), \" \", progressbar.ETA()]\n",
    "pbar = progressbar.ProgressBar(maxval=max_count, widgets=widgets).start()\n",
    "print(\"[INFO] extracting training features...\")\n",
    "q = 0\n",
    "\n",
    "# Iterate over the training images\n",
    "for n_type, typefile in enumerate(dirs_all):\n",
    "\n",
    "    lesiontype = os.listdir(os.path.join(TRAIN_PATH, typefile))\n",
    "    if n_type == 0:\n",
    "        print(\"Lesion\")\n",
    "    else:\n",
    "        print(\"Benign\")\n",
    "\n",
    "    for n, filename in enumerate(lesiontype):\n",
    "        imgpath = os.path.join(TRAIN_PATH, typefile, filename)\n",
    "        image = cv2.imread(imgpath)\n",
    "        image = cv2.GaussianBlur(image, (7, 7), 0)\n",
    "        \n",
    "        if n_type == 0: # les = 1\n",
    "            labels.append(1)\n",
    "        else:          # nev = 0\n",
    "            labels.append(0)\n",
    "\n",
    "        \n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #Contrast Enhancment\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        image_clahe = clahe.apply(gray)\n",
    "        \n",
    "        ###################################################\n",
    "        # Segmentation of skin image\n",
    "        ##################################################\n",
    "        # final_watershed1: segmented mask\n",
    "        # inpaintedWhite: grayscale skin image after hair removal\n",
    "        # inpaintedRGB : RGB skin image after hair removal\n",
    "        \n",
    "        final_watershed1, inpaintedWhite, inpaintedRGB = segment_skin(image_clahe, gray,image)        \n",
    "                \n",
    "        '''\n",
    "            Feature Extraction\n",
    "        '''\n",
    "        \n",
    "        ########################################################\n",
    "        # Hu moments - shape descriptor\n",
    "        ########################################################        \n",
    "        \n",
    "        huMoments = humoments_fun(final_watershed1)\n",
    "        \n",
    "        if n_type == 0 and n == 0:\n",
    "            humoments_feature = huMoments                        \n",
    "        else:\n",
    "            humoments_feature = np.concatenate((humoments_feature, huMoments), axis=1)            \n",
    "        \n",
    "        \n",
    "        ###########################################\n",
    "        # Mean, std, skewness and kurtosis of each channel\n",
    "        ###########################################        \n",
    "        \n",
    "        # Sliding window        \n",
    "        meanstd_window = []\n",
    "        for (x, y, window) in sliding_window(inpaintedRGB, windowSize=(winW, winH), no_channels =3):\n",
    "            # extract features from the windows and concatinate them\n",
    "            meanstd = meanstd_fun(window)\n",
    "            if x == 0 and y == 0:\n",
    "                meanstd_window = meanstd\n",
    "            else:\n",
    "                meanstd_window = np.concatenate((meanstd_window, meanstd),axis=0) \n",
    "                        \n",
    "        if n_type == 0 and n == 0:\n",
    "            meanstd_feature = meanstd_window\n",
    "        else:\n",
    "            meanstd_feature = np.concatenate((meanstd_feature, meanstd_window),axis=1)                     \n",
    "        \n",
    "       ###########################################\n",
    "        # Color Histogram of RGB, HSV and LAB\n",
    "        ###########################################                   \n",
    "            \n",
    "        # Sliding window        \n",
    "        color_hist_window = []\n",
    "        for (x, y, window) in sliding_window(inpaintedRGB, windowSize=(winW, winH),no_channels =3):\n",
    "            # extract features from the windows and concatinate them\n",
    "            color_hist = color_hist_fun(window)\n",
    "            if x == 0 and y == 0:\n",
    "                color_hist_window = color_hist\n",
    "            else:\n",
    "                color_hist_window = np.concatenate((color_hist_window, color_hist),axis=0) \n",
    "                \n",
    "        if n_type == 0 and n == 0:\n",
    "            color_hist_feature = color_hist_window\n",
    "        else:\n",
    "            color_hist_feature = np.concatenate((color_hist_feature, color_hist_window), axis=1) \n",
    "        \n",
    "        ###########################################\n",
    "        # LBP features - texture descriptor\n",
    "        ###########################################\n",
    "        \n",
    "        # Sliding window        \n",
    "        hist_window = []\n",
    "        for (x, y, window) in sliding_window(inpaintedWhite, windowSize=(winW, winH),no_channels =1):\n",
    "            # extract features from the windows and concatinate them\n",
    "            \n",
    "            hist = lbp_fun(window)\n",
    "            if x == 0 and y == 0:\n",
    "                hist_window = hist\n",
    "            else:\n",
    "                hist_window = np.concatenate((hist_window, hist),axis=0)\n",
    "                \n",
    "        if n_type == 0 and n == 0:\n",
    "            lbp_feature = hist_window\n",
    "        else:\n",
    "            lbp_feature = np.concatenate((lbp_feature, hist_window),axis=1) \n",
    "            \n",
    "            \n",
    "        ###########################################\n",
    "        # GLCM based statistical descriptors - texture descriptor        \n",
    "        ###########################################\n",
    "        # calculate haralick texture features for 4 types of adjacency\n",
    "        \n",
    "        # Sliding window        \n",
    "        glcm_f_window = []\n",
    "        for (x, y, window) in sliding_window(inpaintedWhite, windowSize=(winW, winH),no_channels =1):\n",
    "            # extract features from the windows and concatinate them\n",
    "            \n",
    "            glcm_f = glcm_fun(window)\n",
    "            if x == 0 and y == 0:\n",
    "                glcm_f_window = glcm_f\n",
    "            else:\n",
    "                glcm_f_window = np.concatenate((glcm_f_window, glcm_f),axis=0)\n",
    "                \n",
    "        if n_type == 0 and n == 0:\n",
    "            glcm_feature = glcm_f_window\n",
    "        else:\n",
    "            glcm_feature = np.concatenate((glcm_feature, glcm_f_window), axis=1)     \n",
    "        \n",
    "        ###########################################\n",
    "        # Gabor features - texture descriptor\n",
    "        ###########################################        \n",
    "        \n",
    "        # Sliding window        \n",
    "        gabor_window = []\n",
    "        for (x, y, window) in sliding_window(inpaintedWhite, windowSize=(winW, winH),no_channels =1):\n",
    "            # extract features from the windows and concatinate them\n",
    "            \n",
    "            gabor_f = gabor_feature_fun(window, gabor_kernels)\n",
    "            if x == 0 and y == 0:\n",
    "                gabor_window = gabor_f\n",
    "            else:\n",
    "                gabor_window = np.concatenate((gabor_window, gabor_f),axis=0)\n",
    "        gabor_window = np.expand_dims(gabor_window, axis=-1)        \n",
    "        \n",
    "        if n_type == 0 and n == 0:\n",
    "            gabor_feature = gabor_window\n",
    "        else:\n",
    "            gabor_feature = np.concatenate((gabor_feature, gabor_window),axis=1) \n",
    "        \n",
    "        ###################################################\n",
    "        # HOG features - structure and texture descriptor\n",
    "        ###################################################\n",
    "        # Sliding window        \n",
    "        hog_window = []\n",
    "        for (x, y, window) in sliding_window(inpaintedWhite, windowSize=(winW, winH),no_channels =1):\n",
    "            # extract features from the windows and concatinate them\n",
    "            \n",
    "            hog_f = hog_fun(window)\n",
    "            if x == 0 and y == 0:\n",
    "                hog_window = hog_f\n",
    "            else:\n",
    "                hog_window = np.concatenate((hog_window, hog_f),axis=0)\n",
    "        hog_window = np.expand_dims(hog_window, axis=-1)                        \n",
    "            \n",
    "        if n_type == 0 and n == 0:\n",
    "            hog_feature = hog_window\n",
    "        else:\n",
    "            hog_feature = np.concatenate((hog_feature, hog_window), axis=1)                           \n",
    "        \n",
    "        #Progress Bar\n",
    "        q += 1\n",
    "        pbar.update(q) \n",
    "\n",
    "# Transpose so that the feature vector has (#no_samples,#no_features) shape        \n",
    "humoments_feature = np.transpose(humoments_feature)\n",
    "lbp_feature = np.transpose(lbp_feature)\n",
    "meanstd_feature = np.transpose(meanstd_feature)\n",
    "glcm_feature = np.transpose(glcm_feature)\n",
    "gabor_feature = np.transpose(gabor_feature)\n",
    "color_hist_feature = np.transpose(color_hist_feature)\n",
    "hog_feature = np.transpose(hog_feature)\n",
    "\n",
    "pbar.finish()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features from testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs_all = os.listdir(VAL_PATH)\n",
    "dirs_all.sort(key=natural_keys)\n",
    "\n",
    "max_count = 1015\n",
    "\n",
    "humoments_feature_val = []\n",
    "meanstd_feature_val = []\n",
    "lbp_feature_val = []\n",
    "glcm_feature_val = []\n",
    "gabor_feature_val = []\n",
    "color_hist_feature_val = []\n",
    "hog_feature_val = []\n",
    "labels_val = []\n",
    "\n",
    "# set up the progress bar\n",
    "widgets = [\"Reading: \", progressbar.Percentage(), \" \", progressbar.Bar(), \" \", progressbar.ETA()]\n",
    "pbar = progressbar.ProgressBar(maxval=max_count, widgets=widgets).start()\n",
    "print(\"[INFO] extracting validation features...\")\n",
    "q = 0\n",
    "\n",
    "#Iterate over the testing images\n",
    "for n_type, typefile in enumerate(dirs_all):\n",
    "    \n",
    "    #Read Image\n",
    "    imgpath = os.path.join(VAL_PATH, typefile)\n",
    "    image = cv2.imread(imgpath)\n",
    "    \n",
    "    #Gaussian Blurring\n",
    "    image = cv2.GaussianBlur(image, (7, 7), 0)    \n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #Contrast Enhancement\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    image_clahe = clahe.apply(gray)\n",
    "\n",
    "    ###################################################\n",
    "    # Segmentation\n",
    "    ##################################################\n",
    "    # final_watershed1: segmented mask\n",
    "    # inpaintedWhite: grayscale skin image after hair removal\n",
    "    # inpaintedRGB : RGB skin image after hair removal\n",
    "\n",
    "    final_watershed1,inpaintedWhite, inpaintedRGB = segment_skin(image_clahe, gray, image)\n",
    "\n",
    "\n",
    "    '''\n",
    "        Feature Extraction\n",
    "    '''\n",
    "    \n",
    "    ########################################################\n",
    "    # Hu moments - shape descriptor\n",
    "    ########################################################\n",
    "\n",
    "    huMoments = humoments_fun(final_watershed1)\n",
    "        \n",
    "    if n_type == 0:\n",
    "        humoments_feature_val = huMoments                        \n",
    "    else:\n",
    "        humoments_feature_val = np.concatenate((humoments_feature_val, huMoments), axis=1)           \n",
    "    \n",
    "    ########################################\n",
    "    # Mean, std, skewness and kurtosis of each channel    \n",
    "    #########################################\n",
    "    # Sliding window        \n",
    "    meanstd_window = []\n",
    "    for (x, y, window) in sliding_window(inpaintedRGB, windowSize=(winW, winH),no_channels =3):\n",
    "        # extract features from the windows and concatinate them\n",
    "        meanstd = meanstd_fun(window)\n",
    "        if x == 0 and y == 0:\n",
    "            meanstd_window = meanstd\n",
    "        else:\n",
    "            meanstd_window = np.concatenate((meanstd_window, meanstd),axis=0) \n",
    "\n",
    "    if n_type == 0 :\n",
    "        meanstd_feature_val = meanstd_window\n",
    "    else:\n",
    "        meanstd_feature_val = np.concatenate((meanstd_feature_val, meanstd_window),axis=1)\n",
    "\n",
    "    ###########################################\n",
    "    # Color Histogram of RGB, HSV and LAB color spaces\n",
    "    ###########################################\n",
    "\n",
    "    color_hist_window = []\n",
    "    for (x, y, window) in sliding_window(inpaintedRGB, windowSize=(winW, winH),no_channels =3):\n",
    "        # extract features from the windows and concatinate them\n",
    "        color_hist = color_hist_fun(window)\n",
    "        if x == 0 and y == 0:\n",
    "            color_hist_window = color_hist\n",
    "        else:\n",
    "            color_hist_window = np.concatenate((color_hist_window, color_hist),axis=0)                 \n",
    "\n",
    "    if n_type == 0 :\n",
    "        color_hist_feature_val = color_hist_window\n",
    "    else:\n",
    "        color_hist_feature_val = np.concatenate((color_hist_feature_val, color_hist_window), axis=1) \n",
    "\n",
    "    ###########################################\n",
    "    # LBP features - texture descriptor\n",
    "    ###########################################\n",
    "    # Sliding window        \n",
    "    hist_window = []\n",
    "    for (x, y, window) in sliding_window(inpaintedWhite, windowSize=(winW, winH),no_channels =1):\n",
    "        # extract features from the windows and concatinate them\n",
    "\n",
    "        hist = lbp_fun(window)\n",
    "        if x == 0 and y == 0:\n",
    "            hist_window = hist\n",
    "        else:\n",
    "            hist_window = np.concatenate((hist_window, hist),axis=0)\n",
    "\n",
    "    if n_type == 0 :\n",
    "        lbp_feature_val = hist_window\n",
    "    else:\n",
    "        lbp_feature_val = np.concatenate((lbp_feature_val,hist_window),axis=1) \n",
    "\n",
    "\n",
    "    ###########################################\n",
    "    # GLCM based statistical descriptors - texture descriptor    \n",
    "    ###########################################\n",
    "    # calculate haralick texture features for 4 types of adjacency\n",
    "    # Sliding window        \n",
    "    glcm_f_window = []\n",
    "    for (x, y, window) in sliding_window(inpaintedWhite, windowSize=(winW, winH),no_channels =1):\n",
    "        # extract features from the windows and concatinate them\n",
    "\n",
    "        glcm_f = glcm_fun(window)\n",
    "        if x == 0 and y == 0:\n",
    "            glcm_f_window = glcm_f\n",
    "        else:\n",
    "            glcm_f_window = np.concatenate((glcm_f_window, glcm_f),axis=0)\n",
    "\n",
    "    if n_type == 0:\n",
    "        glcm_feature_val = glcm_f_window\n",
    "    else:\n",
    "        glcm_feature_val = np.concatenate((glcm_feature_val, glcm_f_window), axis=1)    \n",
    "                                \n",
    "    ###########################################\n",
    "    # Gabor features - texture descriptor\n",
    "    ###########################################        \n",
    "\n",
    "    # Sliding window        \n",
    "    gabor_window = []\n",
    "    for (x, y, window) in sliding_window(inpaintedWhite, windowSize=(winW, winH),no_channels =1):\n",
    "        # extract features from the windows and concatinate them\n",
    "\n",
    "        gabor_f = gabor_feature_fun(window, gabor_kernels)\n",
    "        if x == 0 and y == 0:\n",
    "            gabor_window = gabor_f\n",
    "        else:\n",
    "            gabor_window = np.concatenate((gabor_window, gabor_f),axis=0)\n",
    "    gabor_window = np.expand_dims(gabor_window, axis=-1)        \n",
    "\n",
    "    if n_type == 0 :\n",
    "        gabor_feature_val = gabor_window\n",
    "    else:\n",
    "        gabor_feature_val = np.concatenate((gabor_feature_val, gabor_window),axis=1) \n",
    "\n",
    "\n",
    "    ##################################################\n",
    "    # HOG features - structure and texture descriptor\n",
    "    ####################################################\n",
    "    hog_window = []\n",
    "    for (x, y, window) in sliding_window(inpaintedWhite, windowSize=(winW, winH),no_channels =1):\n",
    "        # extract features from the windows and concatinate them\n",
    "\n",
    "        hog_f = hog_fun(window)\n",
    "        if x == 0 and y == 0:\n",
    "            hog_window = hog_f\n",
    "        else:\n",
    "            hog_window = np.concatenate((hog_window, hog_f),axis=0)\n",
    "    hog_window = np.expand_dims(hog_window, axis=-1)\n",
    "\n",
    "    if n_type == 0:\n",
    "        hog_feature_val = hog_window\n",
    "    else:\n",
    "        hog_feature_val = np.concatenate((hog_feature_val, hog_window), axis=1)        \n",
    "    \n",
    "    #Progress Bar\n",
    "    q += 1\n",
    "    pbar.update(q) \n",
    "\n",
    "# Transpose so that the feature vector has (#no_samples,#no_features) shape    \n",
    "humoments_feature_val = np.transpose(humoments_feature_val)\n",
    "meanstd_feature_val = np.transpose(meanstd_feature_val)\n",
    "lbp_feature_val = np.transpose(lbp_feature_val)\n",
    "glcm_feature_val = np.transpose(glcm_feature_val)\n",
    "gabor_feature_val = np.transpose(gabor_feature_val)\n",
    "color_hist_feature_val = np.transpose(color_hist_feature_val)\n",
    "hog_feature_val = np.transpose(hog_feature_val)\n",
    "\n",
    "pbar.finish()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humoments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization of Features using mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the mean and std of each features\n",
    "mean_meanstd = np.mean(meanstd_feature, axis=0)\n",
    "std_meanstd = np.std(meanstd_feature, axis=0) + 1e-5\n",
    "mean_lbp = np.mean(lbp_feature, axis=0)\n",
    "std_lbp = np.std(lbp_feature, axis=0)  + 1e-5\n",
    "mean_glcm = np.mean(glcm_feature, axis=0)\n",
    "std_glcm = np.std(glcm_feature, axis=0)  + 1e-5\n",
    "mean_colorhist = np.mean(color_hist_feature, axis=0)\n",
    "std_colorhist = np.std(color_hist_feature, axis=0)  + 1e-5\n",
    "mean_humoments = np.mean(humoments_feature, axis=0)\n",
    "std_humoments = np.std(humoments_feature, axis=0)  + 1e-5\n",
    "mean_gabor = np.mean(gabor_feature, axis=0)\n",
    "std_gabor = np.std(gabor_feature, axis=0)  + 1e-5\n",
    "mean_hog = np.mean(hog_feature, axis=0)\n",
    "std_hog = np.std(hog_feature, axis=0)  + 1e-5\n",
    "\n",
    "# Normalize each training features\n",
    "meanstd_feature_N = (meanstd_feature - mean_meanstd) / std_meanstd\n",
    "lbp_feature_N = (lbp_feature - mean_lbp) / std_lbp\n",
    "glcm_feature_N = (glcm_feature - mean_glcm) / std_glcm\n",
    "color_hist_feature_N = (color_hist_feature - mean_colorhist) / std_colorhist\n",
    "humoments_feature_N = (humoments_feature - mean_humoments) / std_humoments\n",
    "gabor_feature_N = (gabor_feature - mean_gabor) / std_gabor\n",
    "hog_feature_N = (hog_feature - mean_hog) / std_hog\n",
    "\n",
    "# Normalize each test features\n",
    "meanstd_feature_val_N = (meanstd_feature_val - mean_meanstd) / std_meanstd\n",
    "lbp_feature_val_N = (lbp_feature_val - mean_lbp) / std_lbp\n",
    "glcm_feature_val_N = (glcm_feature_val - mean_glcm) / std_glcm\n",
    "color_hist_feature_val_N = (color_hist_feature_val - mean_colorhist) / std_colorhist\n",
    "humoments_feature_val_N = (humoments_feature_val - mean_humoments) / std_humoments\n",
    "gabor_feature_val_N = (gabor_feature_val - mean_gabor) / std_gabor\n",
    "hog_feature_val_N = (hog_feature_val - mean_hog) / std_hog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the normalized features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = np.concatenate((lbp_feature_N, meanstd_feature_N, glcm_feature_N),axis=1) \n",
    "all_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feature_val = np.concatenate((lbp_feature_val_N, meanstd_feature_val_N, glcm_feature_val_N), axis=1) \n",
    "all_feature_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the features using Different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "'linear_svm' for linear svm\n",
    "'svm' for svm with rbf kernel\n",
    "'bagging' for bagging classifier\n",
    "'randomforest' for random forest\n",
    "\n",
    "'''\n",
    "classifier_type = 'svm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "cart = DecisionTreeClassifier(max_depth=5, class_weight=\"balanced\")\n",
    "\n",
    "if classifier_type == 'linear_svm':\n",
    "    model = svm.LinearSVC(C=25.0, random_state=42,class_weight=\"balanced\")\n",
    "    \n",
    "elif(classifier_type == 'bagging'):\n",
    "    model = BaggingClassifier(base_estimator=cart, n_estimators=200, max_samples=0.3)\n",
    "    \n",
    "elif(classifier_type == 'svm'):\n",
    "    model = svm.SVC(C=10.0, kernel= \"rbf\", class_weight=\"balanced\", gamma='auto') #rbf kernel\n",
    "    \n",
    "elif(classifier_type == 'randomforest'):\n",
    "    model = RandomForestClassifier(n_estimators=400,class_weight=\"balanced\",max_depth=5)\n",
    "\n",
    "model.fit(all_features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(all_feature_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "#Confustion Matrix\n",
    "#######################\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(labels, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "#Accuracy\n",
    "#######################\n",
    "conf_mat = confusion_matrix(labels, prediction)\n",
    "acc = (conf_mat[0][0] + conf_mat[1][1]) / len(labels)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "#Display precision, f1-score, senstivity and specificity\n",
    "#####################################################################\n",
    "print(classification_report(labels, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the features using TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "X_embedded = TSNE(n_components=2).fit_transform(meanstd_feature_val)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['r'] * 600 + ['b'] * 600\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes(frameon=False)\n",
    "plt.setp(ax, xticks=(), yticks=())\n",
    "plt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=0.9,\n",
    "                wspace=0.0, hspace=0.0)\n",
    "plt.scatter(X_embedded[:, 0], X_embedded[:, 1],\n",
    "        c=colors, marker=\"x\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maia_aia",
   "language": "python",
   "name": "maia_aia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
